{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7beb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a91326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6800cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampling import *\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355018da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ec372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143f9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_args(parse_args):\n",
    "    x = PrettyTable()\n",
    "    x.field_names = [\"Arg.\", \"Value\"]\n",
    "    for arg in vars(parse_args):\n",
    "        x.add_row([arg, getattr(parse_args, arg)])\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3375dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parse():\n",
    "        parser = argparse.ArgumentParser(description='LiveRec - Douyu')\n",
    "\n",
    "        parser.add_argument('--seed', dest='seed', type=int,\n",
    "            help='Random seed')\n",
    "\n",
    "        parser.add_argument('--batch_size', dest='batch_size', type=int,\n",
    "            help='Batch size - only active if torch is used')\n",
    "        parser.add_argument('--seq_len', dest='seq_len', type=int,\n",
    "            help='Max size of the sequence to consider')\n",
    "\n",
    "        parser.add_argument('--num_heads', dest='num_heads', type=int,\n",
    "            help='Numer of heads to use for multi-heads attention')\n",
    "        parser.add_argument('--num_heads_ctx', dest='num_heads_ctx', type=int,\n",
    "            help='Numer of heads to use for multi-heads attention CTX')\n",
    "\n",
    "\n",
    "        parser.add_argument('--dataset', dest='dataset', \n",
    "            help='Input dataset.')\n",
    " \n",
    "        parser.add_argument('--model', dest='model', type=str,\n",
    "            help='Type of the model')\n",
    "\n",
    "        parser.add_argument('--model_from', dest='mfrom', type=str,\n",
    "            help='Name of the model to load')\n",
    "        parser.add_argument('--model_to', dest='mto', type=str,\n",
    "            help='Name of the model to save')\n",
    "        parser.add_argument('--cache_dir', dest='cache_dir', type=str,\n",
    "            help='Path to save the cached preprocessd dataset')\n",
    " \n",
    "        parser.add_argument('--model_path', dest='model_path', type=str,\n",
    "            help='Path to save the model')\n",
    "        parser.add_argument('--early_stop', dest='early_stop', type=int,\n",
    "            help='Number of iteration without improvment before stop')\n",
    "        parser.add_argument('--ev_sample', dest='ev_sample', type=int,\n",
    "            help='Number of samples for the final evaluation')\n",
    "        parser.add_argument('--device', dest='device', type=str,\n",
    "            help='Pytorch device')\n",
    "\n",
    "        parser.add_argument('--lr', dest='lr', type=float,\n",
    "            help='Learning rate.')\n",
    "        parser.add_argument('--mask_prob', dest='mask_prob', type=float,\n",
    "            help='BERT mask prob.')\n",
    "        parser.add_argument('--l2', dest='l2', type=float,\n",
    "            help='Strength of L2 regularization')\n",
    "        parser.add_argument('--dim', dest='K', type=int,\n",
    "            help='Number of latent factors')\n",
    " \n",
    "        parser.add_argument('--num_iters', dest='num_iter', type=int,\n",
    "            help='Number of training iterations')\n",
    "        parser.add_argument('--num_epochs', dest='num_epochs', type=int,\n",
    "            help='Number of training epochs')\n",
    "        parser.add_argument('--num_att', dest='num_att', type=int,\n",
    "            help='Num attention module for seq encoding')\n",
    "        parser.add_argument('--num_att_ctx', dest='num_att_ctx', type=int,\n",
    "            help='Num attention for ctx module')\n",
    " \n",
    "        parser.add_argument('--topk_att', dest='topk_att', type=int,\n",
    "            help='Items to send to attentive output')\n",
    "\n",
    "        parser.add_argument('--fr_ctx', dest='fr_ctx', nargs='?',\n",
    "            const=True, default=True,\n",
    "            help='')\n",
    "        parser.add_argument('--fr_rep', dest='fr_rep', nargs='?',\n",
    "            const=True, default=False,\n",
    "            help='')\n",
    "        parser.add_argument('--uniform', dest='uniform', nargs='?',\n",
    "            const=True, default=False,\n",
    "            help='')\n",
    "        parser.add_argument('--debug', dest='debug', nargs='?',\n",
    "            const=True, default=False,\n",
    "            help='')\n",
    "#         parser.add_argument('--caching', dest='caching', nargs='?',\n",
    "#             const=True, default=False,\n",
    "#             help='')\n",
    "        parser.add_argument('--caching', dest='caching', nargs='?',\n",
    "            const=True, default=True,\n",
    "            help='')\n",
    "\n",
    "        parser.set_defaults(\n",
    "                        seed=42,\n",
    "                        dataset=\"\",\n",
    "                        lr=0.0005,\n",
    "                        l2=0.1,  \n",
    "                        mask_prob=0.5,  \n",
    "                        batch_size=100, \n",
    "                        num_att=2,\n",
    "                        num_att_ctx=2,\n",
    "                        num_heads=4,\n",
    "                        num_heads_ctx=4,\n",
    "                        num_iter=200,\n",
    "                        seq_len=16,  \n",
    "                        topk_att=64,  \n",
    "                        early_stop=15,  \n",
    "                        K=64,  \n",
    "                        num_epochs=150,\n",
    "#                         model=\"LiveRec\",\n",
    "                        model=\"POP\",\n",
    "                        model_path=\"\",\n",
    "                        mto=\"liverec\",\n",
    "                        device=\"cuda\",\n",
    "                        cache_dir=\"\"\n",
    "                       )\n",
    "\n",
    "\n",
    "        args, unknown = parser.parse_known_args()\n",
    "        return args "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526f32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|      Arg.     |  Value  |\n",
      "+---------------+---------+\n",
      "|      seed     |    42   |\n",
      "|   batch_size  |   100   |\n",
      "|    seq_len    |    16   |\n",
      "|   num_heads   |    4    |\n",
      "| num_heads_ctx |    4    |\n",
      "|    dataset    |         |\n",
      "|     model     |   POP   |\n",
      "|     mfrom     |   None  |\n",
      "|      mto      | liverec |\n",
      "|   cache_dir   |         |\n",
      "|   model_path  |         |\n",
      "|   early_stop  |    15   |\n",
      "|   ev_sample   |   None  |\n",
      "|     device    |   cuda  |\n",
      "|       lr      |  0.0005 |\n",
      "|   mask_prob   |   0.5   |\n",
      "|       l2      |   0.1   |\n",
      "|       K       |    64   |\n",
      "|    num_iter   |   200   |\n",
      "|   num_epochs  |   150   |\n",
      "|    num_att    |    2    |\n",
      "|  num_att_ctx  |    2    |\n",
      "|    topk_att   |    64   |\n",
      "|     fr_ctx    |   True  |\n",
      "|     fr_rep    |  False  |\n",
      "|    uniform    |  False  |\n",
      "|     debug     |  False  |\n",
      "|    caching    |   True  |\n",
      "+---------------+---------+\n"
     ]
    }
   ],
   "source": [
    "args = arg_parse()\n",
    "print_args(args)\n",
    "args.device = torch.device(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669f7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3f5da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users:  11610\n",
      "Num streamers:  47612\n",
      "Num interactions:  5378125\n"
     ]
    }
   ],
   "source": [
    "INFILE = os.path.join(args.dataset,'douyu_10k_min_duration.csv')\n",
    "#user,streamer_id,start,stop\n",
    "cols = [\"user\",\"streamer\",\"start\",\"stop\",\"duration\"]\n",
    "data_fu = pd.read_csv(INFILE, header=None, names=cols)\n",
    "    \n",
    "# Add one for padding\n",
    "data_fu.user = pd.factorize(data_fu.user)[0]+1\n",
    "data_fu['streamer_raw'] = data_fu.streamer\n",
    "data_fu.streamer = pd.factorize(data_fu.streamer)[0]+1\n",
    "print(\"Num users: \", data_fu.user.nunique())\n",
    "print(\"Num streamers: \", data_fu.streamer.nunique())\n",
    "print(\"Num interactions: \", len(data_fu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5368ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 87839, 1, 87840)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fu.start.min(),data_fu.start.max(),data_fu.stop.min(),data_fu.stop.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cad0a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.M = data_fu.user.max()+1 # users\n",
    "args.N = data_fu.streamer.max()+2 # items\n",
    "args.D = data_fu.duration.max()+1 # duration\n",
    "\n",
    "data_temp = data_fu.drop_duplicates(subset=['streamer','streamer_raw'])\n",
    "umap      = dict(zip(data_temp.streamer_raw.tolist(),data_temp.streamer.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fafe00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11611, 47614, 2883)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.M ,args.N ,args.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d96521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps:  87840\n"
     ]
    }
   ],
   "source": [
    "# Splitting and caching\n",
    "max_step = max(data_fu.start.max(),data_fu.stop.max())\n",
    "print(\"Num timesteps: \", max_step)\n",
    "args.max_step = max_step\n",
    "args.pivot_1  = max_step-500\n",
    "args.pivot_2  = max_step-250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8bea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching availability\n",
      "max_avail:  446\n"
     ]
    }
   ],
   "source": [
    "print(\"caching availability\")\n",
    "ts = {}\n",
    "max_avail = 0\n",
    "for s in range(max_step):\n",
    "    all_av = data_fu[(data_fu.start<=s) & (data_fu.stop>s)].streamer.unique().tolist()\n",
    "    ts[s] = all_av\n",
    "    max_avail = max(max_avail,len(ts[s]))\n",
    "args.max_avail = max_avail\n",
    "args.ts = ts\n",
    "print(\"max_avail: \", max_avail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674384c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute availability matrix of size (num_timesteps x max_available)\n",
    "max_av   = max([len(v) for k,v in args.ts.items()])\n",
    "max_step = max([k for k,v in args.ts.items()])+1\n",
    "av_tens = torch.zeros(max_step,max_av).type(torch.long)\n",
    "for k,v in args.ts.items():\n",
    "    av_tens[k,:len(v)] = torch.LongTensor(v)\n",
    "args.av_tens = av_tens.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6ab1041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>streamer</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>duration</th>\n",
       "      <th>streamer_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81824</td>\n",
       "      <td>81825</td>\n",
       "      <td>2</td>\n",
       "      <td>1211089da67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>73720</td>\n",
       "      <td>73721</td>\n",
       "      <td>1</td>\n",
       "      <td>eb5bf69ab60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81825</td>\n",
       "      <td>81834</td>\n",
       "      <td>18</td>\n",
       "      <td>1211089da67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>73673</td>\n",
       "      <td>73676</td>\n",
       "      <td>4</td>\n",
       "      <td>eb5bf69ab60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81745</td>\n",
       "      <td>81750</td>\n",
       "      <td>9</td>\n",
       "      <td>1211089da67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378120</th>\n",
       "      <td>11610</td>\n",
       "      <td>8849</td>\n",
       "      <td>21366</td>\n",
       "      <td>21368</td>\n",
       "      <td>2</td>\n",
       "      <td>80ec36cddc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378121</th>\n",
       "      <td>11610</td>\n",
       "      <td>8849</td>\n",
       "      <td>21364</td>\n",
       "      <td>21367</td>\n",
       "      <td>4</td>\n",
       "      <td>80ec36cddc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378122</th>\n",
       "      <td>11610</td>\n",
       "      <td>8849</td>\n",
       "      <td>21319</td>\n",
       "      <td>21332</td>\n",
       "      <td>24</td>\n",
       "      <td>80ec36cddc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378123</th>\n",
       "      <td>11610</td>\n",
       "      <td>8849</td>\n",
       "      <td>21362</td>\n",
       "      <td>21365</td>\n",
       "      <td>4</td>\n",
       "      <td>80ec36cddc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378124</th>\n",
       "      <td>11610</td>\n",
       "      <td>8849</td>\n",
       "      <td>21303</td>\n",
       "      <td>21312</td>\n",
       "      <td>16</td>\n",
       "      <td>80ec36cddc2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5378125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user  streamer  start   stop  duration streamer_raw\n",
       "0            1         1  81824  81825         2  1211089da67\n",
       "1            1         2  73720  73721         1  eb5bf69ab60\n",
       "2            1         1  81825  81834        18  1211089da67\n",
       "3            1         2  73673  73676         4  eb5bf69ab60\n",
       "4            1         1  81745  81750         9  1211089da67\n",
       "...        ...       ...    ...    ...       ...          ...\n",
       "5378120  11610      8849  21366  21368         2  80ec36cddc2\n",
       "5378121  11610      8849  21364  21367         4  80ec36cddc2\n",
       "5378122  11610      8849  21319  21332        24  80ec36cddc2\n",
       "5378123  11610      8849  21362  21365         4  80ec36cddc2\n",
       "5378124  11610      8849  21303  21312        16  80ec36cddc2\n",
       "\n",
       "[5378125 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ab1a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch,args):\n",
    "    # returns a [batch x seq x feats] tensor\n",
    "    # feats: [padded_positions,positions,inputs_ts,items,users,targets,targets_ts]\n",
    "\n",
    "    bs = len(batch)\n",
    "    feat_len = len(batch[0])\n",
    "    batch_seq = torch.zeros(bs,args.seq_len, feat_len, dtype=torch.long)\n",
    "    for ib,b in enumerate(batch):\n",
    "        for ifeat,feat in enumerate(b):\n",
    "            batch_seq[ib,b[0],ifeat] = feat\n",
    "    return batch_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "440fc1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    lengths = torch.tensor([ t.shape[0] for t in batch ]).to(device)\n",
    "    ## padd\n",
    "    batch = [ torch.Tensor(t).to(device) for t in batch ]\n",
    "    batch = torch.nn.utils.rnn.pad_sequence(batch)\n",
    "    ## compute mask\n",
    "    mask = (batch != 0).to(device)\n",
    "    return batch, lengths, mask\n",
    "\n",
    "def get_sequences(_data, _p1, _p2, args, max_u=int(10e9)):\n",
    "    data_list = []\n",
    "\n",
    "    _data = _data[_data.stop<_p2].copy()\n",
    "    \n",
    "    grouped = _data.groupby('user')\n",
    "    for user_id, group in tqdm(grouped):\n",
    "        group = group.sort_values('start')\n",
    "        group = group.tail(args.seq_len+1)\n",
    "        if len(group)<2: continue\n",
    "\n",
    "        group = group.reset_index(drop=True) \n",
    "        \n",
    "        # Get last interaction\n",
    "        last_el = group.tail(1)\n",
    "        yt = last_el.start.values[0]\n",
    "        group.drop(last_el.index,inplace=True)\n",
    "\n",
    "        # avoid including train in test/validation\n",
    "        if yt < _p1 or yt >= _p2: continue\n",
    "\n",
    "        padlen = args.seq_len - len(group)\n",
    "\n",
    "        # sequence input features\n",
    "        positions  = torch.LongTensor(group.index.values)\n",
    "        inputs_ts  = torch.LongTensor(group.start.values)\n",
    "        items      = torch.LongTensor(group['streamer'].values)\n",
    "        duration   = torch.LongTensor(group['duration'].values)\n",
    "        users      = torch.LongTensor(group.user.values)\n",
    "        bpad       = torch.LongTensor(group.index.values + padlen)\n",
    "        diff_du    = torch.LongTensor(np.diff(np.array(inputs_ts[1:].tolist() + [last_el.start.values[0]])))\n",
    "\n",
    "        # sequence output features\n",
    "        targets    = torch.LongTensor(items[1:].tolist() + [last_el.streamer.values[0]])\n",
    "        targets_ts = torch.LongTensor(inputs_ts[1:].tolist() + [last_el.start.values[0]])\n",
    "\n",
    "        data_list.append([bpad,positions,inputs_ts,items,users,targets,targets_ts,duration])\n",
    "\n",
    "        # stop if user limit is reached\n",
    "        if len(data_list)>max_u: break\n",
    "\n",
    "    return SequenceDataset(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26a169f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_tr = os.path.join(args.cache_dir,\"douyu_10k_min_dur_tr.p\")\n",
    "cache_te = os.path.join(args.cache_dir,\"douyu_10k_min_dur_te.p\")\n",
    "cache_va = os.path.join(args.cache_dir,\"douyu_10k_min_dur_val.p\")\n",
    "\n",
    "mu = int(10e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711bd034",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 11591/11591 [00:06<00:00, 1690.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11600/11600 [00:04<00:00, 2418.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 11610/11610 [00:04<00:00, 2331.05it/s]\n"
     ]
    }
   ],
   "source": [
    "datalist_tr = get_sequences(data_fu,0,args.pivot_1,args,mu)\n",
    "datalist_va = get_sequences(data_fu,args.pivot_1,args.pivot_2,args,mu)\n",
    "datalist_te = get_sequences(data_fu,args.pivot_2,max_step,args,mu)\n",
    "    \n",
    "pickle.dump(datalist_te, open(cache_te, \"wb\"))\n",
    "pickle.dump(datalist_tr, open(cache_tr, \"wb\"))\n",
    "pickle.dump(datalist_va, open(cache_va, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2ddf6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(datalist_tr,batch_size=args.batch_size,\n",
    "                              collate_fn=lambda x: custom_collate(x,args))\n",
    "val_loader   = DataLoader(datalist_va,batch_size=args.batch_size,\n",
    "                              collate_fn=lambda x: custom_collate(x,args))\n",
    "test_loader  = DataLoader(datalist_te,batch_size=args.batch_size,\n",
    "                              collate_fn=lambda x: custom_collate(x,args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a27991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d99cde8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from eval import *\n",
    "from data import *\n",
    "from modify_duration_embedding_v1 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd7feecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model='LiveRec_dur_emb_v1'\n",
    "MPATH6,MODEL6 = get_model_type_new(args)\n",
    "MPATH6,MODEL6\n",
    "model6 = MODEL6(args).to(args.device)\n",
    "optimizer = optim.Adam(model6.parameters(),lr=args.lr,weight_decay=args.l2)\n",
    "\n",
    "best_val = 0.0\n",
    "best_max = args.early_stop\n",
    "best_cnt = best_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9bbbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.34it/s]\n",
      "17it [00:02,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 2.00647\n",
      "all: h@1: 0.18914 h@5: 0.27944 h@10: 0.32825 ndcg@1: 0.18914 ndcg@5: 0.23617 ndcg@10: 0.25166\n",
      "new: h@1: 0.00598 h@5: 0.03438 h@10: 0.06726 ndcg@1: 0.00598 ndcg@5: 0.01913 ndcg@10: 0.02949\n",
      "rep: h@1: 0.31546 h@5: 0.44845 h@10: 0.50825 ndcg@1: 0.31546 ndcg@5: 0.38586 ndcg@10: 0.40489\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.41it/s]\n",
      "17it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 1.55432\n",
      "all: h@1: 0.13789 h@5: 0.28005 h@10: 0.33679 ndcg@1: 0.13789 ndcg@5: 0.21049 ndcg@10: 0.22896\n",
      "new: h@1: 0.00897 h@5: 0.06876 h@10: 0.10613 ndcg@1: 0.00897 ndcg@5: 0.03747 ndcg@10: 0.04935\n",
      "rep: h@1: 0.22680 h@5: 0.42577 h@10: 0.49588 ndcg@1: 0.22680 ndcg@5: 0.32982 ndcg@10: 0.35284\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.35it/s]\n",
      "17it [00:02,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 1.32334\n",
      "all: h@1: 0.12203 h@5: 0.27578 h@10: 0.34899 ndcg@1: 0.12203 ndcg@5: 0.19953 ndcg@10: 0.22340\n",
      "new: h@1: 0.01794 h@5: 0.08221 h@10: 0.11958 ndcg@1: 0.01794 ndcg@5: 0.04807 ndcg@10: 0.06015\n",
      "rep: h@1: 0.19381 h@5: 0.40928 h@10: 0.50722 ndcg@1: 0.19381 ndcg@5: 0.30400 ndcg@10: 0.33599\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.37it/s]\n",
      "17it [00:02,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 1.27481\n",
      "all: h@1: 0.12081 h@5: 0.28371 h@10: 0.35937 ndcg@1: 0.12081 ndcg@5: 0.20219 ndcg@10: 0.22685\n",
      "new: h@1: 0.01345 h@5: 0.08221 h@10: 0.12407 ndcg@1: 0.01345 ndcg@5: 0.04837 ndcg@10: 0.06175\n",
      "rep: h@1: 0.19485 h@5: 0.42268 h@10: 0.52165 ndcg@1: 0.19485 ndcg@5: 0.30829 ndcg@10: 0.34071\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.34it/s]\n",
      "17it [00:02,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 1.25767\n",
      "all: h@1: 0.13057 h@5: 0.29530 h@10: 0.36242 ndcg@1: 0.13057 ndcg@5: 0.21440 ndcg@10: 0.23646\n",
      "new: h@1: 0.01345 h@5: 0.08969 h@10: 0.13154 ndcg@1: 0.01345 ndcg@5: 0.05256 ndcg@10: 0.06595\n",
      "rep: h@1: 0.21134 h@5: 0.43711 h@10: 0.52165 ndcg@1: 0.21134 ndcg@5: 0.32602 ndcg@10: 0.35406\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.35it/s]\n",
      "17it [00:02,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 1.24602\n",
      "all: h@1: 0.14338 h@5: 0.30262 h@10: 0.36852 ndcg@1: 0.14338 ndcg@5: 0.22442 ndcg@10: 0.24608\n",
      "new: h@1: 0.01794 h@5: 0.08969 h@10: 0.13752 ndcg@1: 0.01794 ndcg@5: 0.05418 ndcg@10: 0.06942\n",
      "rep: h@1: 0.22990 h@5: 0.44948 h@10: 0.52784 ndcg@1: 0.22990 ndcg@5: 0.34183 ndcg@10: 0.36792\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.33it/s]\n",
      "17it [00:02,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 1.23497\n",
      "all: h@1: 0.13911 h@5: 0.30872 h@10: 0.37279 ndcg@1: 0.13911 ndcg@5: 0.22425 ndcg@10: 0.24493\n",
      "new: h@1: 0.01943 h@5: 0.09417 h@10: 0.13752 ndcg@1: 0.01943 ndcg@5: 0.05640 ndcg@10: 0.07014\n",
      "rep: h@1: 0.22165 h@5: 0.45670 h@10: 0.53505 ndcg@1: 0.22165 ndcg@5: 0.34002 ndcg@10: 0.36547\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.34it/s]\n",
      "17it [00:02,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 1.22688\n",
      "all: h@1: 0.14643 h@5: 0.31483 h@10: 0.37584 ndcg@1: 0.14643 ndcg@5: 0.23303 ndcg@10: 0.25287\n",
      "new: h@1: 0.01495 h@5: 0.09716 h@10: 0.13602 ndcg@1: 0.01495 ndcg@5: 0.05598 ndcg@10: 0.06839\n",
      "rep: h@1: 0.23711 h@5: 0.46495 h@10: 0.54124 ndcg@1: 0.23711 ndcg@5: 0.35514 ndcg@10: 0.38010\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.31it/s]\n",
      "17it [00:02,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 1.22016\n",
      "all: h@1: 0.15619 h@5: 0.31910 h@10: 0.38133 ndcg@1: 0.15619 ndcg@5: 0.23958 ndcg@10: 0.25986\n",
      "new: h@1: 0.01794 h@5: 0.08969 h@10: 0.13453 ndcg@1: 0.01794 ndcg@5: 0.05423 ndcg@10: 0.06861\n",
      "rep: h@1: 0.25155 h@5: 0.47732 h@10: 0.55155 ndcg@1: 0.25155 ndcg@5: 0.36742 ndcg@10: 0.39176\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:27<00:00,  4.18it/s]\n",
      "17it [00:02,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 1.21260\n",
      "all: h@1: 0.16595 h@5: 0.32703 h@10: 0.38621 ndcg@1: 0.16595 ndcg@5: 0.24980 ndcg@10: 0.26911\n",
      "new: h@1: 0.01644 h@5: 0.08969 h@10: 0.13602 ndcg@1: 0.01644 ndcg@5: 0.05386 ndcg@10: 0.06865\n",
      "rep: h@1: 0.26907 h@5: 0.49072 h@10: 0.55876 ndcg@1: 0.26907 ndcg@5: 0.38494 ndcg@10: 0.40736\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.39it/s]\n",
      "17it [00:02,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Loss: 1.20860\n",
      "all: h@1: 0.17694 h@5: 0.33801 h@10: 0.38865 ndcg@1: 0.17694 ndcg@5: 0.26081 ndcg@10: 0.27739\n",
      "new: h@1: 0.01495 h@5: 0.08819 h@10: 0.13752 ndcg@1: 0.01495 ndcg@5: 0.05257 ndcg@10: 0.06864\n",
      "rep: h@1: 0.28866 h@5: 0.51031 h@10: 0.56186 ndcg@1: 0.28866 ndcg@5: 0.40443 ndcg@10: 0.42136\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.38it/s]\n",
      "17it [00:02,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Loss: 1.20245\n",
      "all: h@1: 0.18182 h@5: 0.33618 h@10: 0.39231 ndcg@1: 0.18182 ndcg@5: 0.26374 ndcg@10: 0.28208\n",
      "new: h@1: 0.01943 h@5: 0.08819 h@10: 0.13303 ndcg@1: 0.01943 ndcg@5: 0.05475 ndcg@10: 0.06944\n",
      "rep: h@1: 0.29381 h@5: 0.50722 h@10: 0.57113 ndcg@1: 0.29381 ndcg@5: 0.40788 ndcg@10: 0.42874\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.41it/s]\n",
      "17it [00:02,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Loss: 1.19846\n",
      "all: h@1: 0.19402 h@5: 0.34411 h@10: 0.39658 ndcg@1: 0.19402 ndcg@5: 0.27325 ndcg@10: 0.29031\n",
      "new: h@1: 0.01345 h@5: 0.08969 h@10: 0.13453 ndcg@1: 0.01345 ndcg@5: 0.05293 ndcg@10: 0.06707\n",
      "rep: h@1: 0.31856 h@5: 0.51959 h@10: 0.57732 ndcg@1: 0.31856 ndcg@5: 0.42520 ndcg@10: 0.44428\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.38it/s]\n",
      "17it [00:02,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Loss: 1.19366\n",
      "all: h@1: 0.19646 h@5: 0.34411 h@10: 0.39536 ndcg@1: 0.19646 ndcg@5: 0.27497 ndcg@10: 0.29182\n",
      "new: h@1: 0.01495 h@5: 0.08520 h@10: 0.13303 ndcg@1: 0.01495 ndcg@5: 0.05226 ndcg@10: 0.06807\n",
      "rep: h@1: 0.32165 h@5: 0.52268 h@10: 0.57629 ndcg@1: 0.32165 ndcg@5: 0.42856 ndcg@10: 0.44614\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.38it/s]\n",
      "17it [00:02,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 014, Loss: 1.18875\n",
      "all: h@1: 0.19402 h@5: 0.34960 h@10: 0.40574 ndcg@1: 0.19402 ndcg@5: 0.27620 ndcg@10: 0.29443\n",
      "new: h@1: 0.01495 h@5: 0.08819 h@10: 0.14051 ndcg@1: 0.01495 ndcg@5: 0.05352 ndcg@10: 0.07046\n",
      "rep: h@1: 0.31753 h@5: 0.52990 h@10: 0.58866 ndcg@1: 0.31753 ndcg@5: 0.42977 ndcg@10: 0.44890\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.41it/s]\n",
      "17it [00:02,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 015, Loss: 1.18487\n",
      "all: h@1: 0.20866 h@5: 0.35143 h@10: 0.40574 ndcg@1: 0.20866 ndcg@5: 0.28450 ndcg@10: 0.30217\n",
      "new: h@1: 0.01644 h@5: 0.08819 h@10: 0.14051 ndcg@1: 0.01644 ndcg@5: 0.05395 ndcg@10: 0.07091\n",
      "rep: h@1: 0.34124 h@5: 0.53299 h@10: 0.58866 ndcg@1: 0.34124 ndcg@5: 0.44352 ndcg@10: 0.46166\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.41it/s]\n",
      "17it [00:02,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 016, Loss: 1.17983\n",
      "all: h@1: 0.21477 h@5: 0.36364 h@10: 0.41245 ndcg@1: 0.21477 ndcg@5: 0.29333 ndcg@10: 0.30900\n",
      "new: h@1: 0.01495 h@5: 0.09268 h@10: 0.14200 ndcg@1: 0.01495 ndcg@5: 0.05568 ndcg@10: 0.07142\n",
      "rep: h@1: 0.35258 h@5: 0.55052 h@10: 0.59897 ndcg@1: 0.35258 ndcg@5: 0.45723 ndcg@10: 0.47286\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.39it/s]\n",
      "17it [00:02,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 017, Loss: 1.17520\n",
      "all: h@1: 0.22087 h@5: 0.35998 h@10: 0.41062 ndcg@1: 0.22087 ndcg@5: 0.29513 ndcg@10: 0.31142\n",
      "new: h@1: 0.01495 h@5: 0.08819 h@10: 0.13752 ndcg@1: 0.01495 ndcg@5: 0.05471 ndcg@10: 0.07038\n",
      "rep: h@1: 0.36289 h@5: 0.54742 h@10: 0.59897 ndcg@1: 0.36289 ndcg@5: 0.46094 ndcg@10: 0.47766\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.36it/s]\n",
      "17it [00:02,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 018, Loss: 1.17319\n",
      "all: h@1: 0.22026 h@5: 0.36852 h@10: 0.41977 ndcg@1: 0.22026 ndcg@5: 0.29890 ndcg@10: 0.31532\n",
      "new: h@1: 0.01794 h@5: 0.09268 h@10: 0.14200 ndcg@1: 0.01794 ndcg@5: 0.05693 ndcg@10: 0.07300\n",
      "rep: h@1: 0.35979 h@5: 0.55876 h@10: 0.61134 ndcg@1: 0.35979 ndcg@5: 0.46577 ndcg@10: 0.48245\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.39it/s]\n",
      "17it [00:02,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 019, Loss: 1.16833\n",
      "all: h@1: 0.22575 h@5: 0.37401 h@10: 0.42587 ndcg@1: 0.22575 ndcg@5: 0.30460 ndcg@10: 0.32124\n",
      "new: h@1: 0.01943 h@5: 0.09865 h@10: 0.14798 ndcg@1: 0.01943 ndcg@5: 0.06024 ndcg@10: 0.07597\n",
      "rep: h@1: 0.36804 h@5: 0.56392 h@10: 0.61753 ndcg@1: 0.36804 ndcg@5: 0.47314 ndcg@10: 0.49040\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.39it/s]\n",
      "17it [00:02,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 020, Loss: 1.16498\n",
      "all: h@1: 0.23307 h@5: 0.37706 h@10: 0.43258 ndcg@1: 0.23307 ndcg@5: 0.30913 ndcg@10: 0.32704\n",
      "new: h@1: 0.01943 h@5: 0.09716 h@10: 0.15546 ndcg@1: 0.01943 ndcg@5: 0.05890 ndcg@10: 0.07759\n",
      "rep: h@1: 0.38041 h@5: 0.57010 h@10: 0.62371 ndcg@1: 0.38041 ndcg@5: 0.48171 ndcg@10: 0.49909\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.42it/s]\n",
      "17it [00:02,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 021, Loss: 1.16394\n",
      "all: h@1: 0.24405 h@5: 0.38011 h@10: 0.43075 ndcg@1: 0.24405 ndcg@5: 0.31568 ndcg@10: 0.33208\n",
      "new: h@1: 0.02093 h@5: 0.09716 h@10: 0.15097 ndcg@1: 0.02093 ndcg@5: 0.05975 ndcg@10: 0.07743\n",
      "rep: h@1: 0.39794 h@5: 0.57526 h@10: 0.62371 ndcg@1: 0.39794 ndcg@5: 0.49220 ndcg@10: 0.50771\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.39it/s]\n",
      "17it [00:02,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 022, Loss: 1.15879\n",
      "all: h@1: 0.24710 h@5: 0.39414 h@10: 0.44417 ndcg@1: 0.24710 ndcg@5: 0.32533 ndcg@10: 0.34137\n",
      "new: h@1: 0.02691 h@5: 0.11061 h@10: 0.17040 ndcg@1: 0.02691 ndcg@5: 0.06793 ndcg@10: 0.08708\n",
      "rep: h@1: 0.39897 h@5: 0.58969 h@10: 0.63299 ndcg@1: 0.39897 ndcg@5: 0.50286 ndcg@10: 0.51675\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:25<00:00,  4.41it/s]\n",
      "17it [00:02,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 023, Loss: 1.15335\n",
      "all: h@1: 0.24405 h@5: 0.39597 h@10: 0.44539 ndcg@1: 0.24405 ndcg@5: 0.32605 ndcg@10: 0.34211\n",
      "new: h@1: 0.01943 h@5: 0.10314 h@10: 0.16442 ndcg@1: 0.01943 ndcg@5: 0.06253 ndcg@10: 0.08243\n",
      "rep: h@1: 0.39897 h@5: 0.59794 h@10: 0.63918 ndcg@1: 0.39897 ndcg@5: 0.50781 ndcg@10: 0.52120\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:26<00:00,  4.36it/s]\n",
      "17it [00:02,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 024, Loss: 1.15093\n",
      "all: h@1: 0.25259 h@5: 0.40024 h@10: 0.44295 ndcg@1: 0.25259 ndcg@5: 0.33196 ndcg@10: 0.34590\n",
      "new: h@1: 0.01943 h@5: 0.10613 h@10: 0.15994 ndcg@1: 0.01943 ndcg@5: 0.06368 ndcg@10: 0.08129\n",
      "rep: h@1: 0.41340 h@5: 0.60309 h@10: 0.63814 ndcg@1: 0.41340 ndcg@5: 0.51698 ndcg@10: 0.52839\n",
      "ratio:  0.5918242830994509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████████████████████████████████████████▉         | 101/114 [00:23<00:03,  3.96it/s]"
     ]
    }
   ],
   "source": [
    "print(\"training...\")\n",
    "for epoch in range(args.num_epochs):\n",
    "    loss_all = 0.0; loss_cnt = 0\n",
    "    model6.train()\n",
    "    for data in tqdm(train_loader):\n",
    "        data = data.to(args.device)\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss = model6.train_step(data)\n",
    "            \n",
    "        loss_all += loss.item()\n",
    "        loss_cnt += (data[:,:,5]!=0).sum()\n",
    "        \n",
    "#         loss1 = loss.detach_().requires_grad_(True)\n",
    "#         loss1.backward()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if torch.isnan(loss):\n",
    "            print(\"loss is nan !\") \n",
    "    \n",
    "    scores = compute_recall(model6, val_loader, args, maxit=500)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, loss_all/loss_cnt))\n",
    "    print_scores(scores)\n",
    "    \n",
    "    hall = scores['all']['h01']\n",
    "    if hall>best_val:\n",
    "        best_val = hall\n",
    "        torch.save(model6.state_dict(), MPATH6)\n",
    "        best_cnt = best_max\n",
    "    else:\n",
    "        best_cnt -= 1\n",
    "        if best_cnt == 0:\n",
    "            break\n",
    "    \n",
    "model6 = MODEL6(args).to(args.device)\n",
    "model6.load_state_dict(torch.load(MPATH6))\n",
    "    \n",
    "scores = compute_recall(model6, test_loader, args)\n",
    "print(\"Final score\")\n",
    "print(\"=\"*11)\n",
    "print('Epoch: {:03d}, Loss: {:.5f}'.format(epoch, loss_all/loss_cnt))\n",
    "print_scores(scores)\n",
    "save_scores(scores,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da39e577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
